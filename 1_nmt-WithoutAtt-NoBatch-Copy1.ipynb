{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA 1011 Lab 8 Neural Machine Translation with Seq2Seq model and Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from the PyTorch tutorials (https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will be teaching a neural network to translate from French to English.\n",
    "::\n",
    "\n",
    "    [KEY: > input, = target, < output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "... to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the `sequence\n",
    "to sequence network <http://arxiv.org/abs/1409.3215>`__, in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "\n",
    "To improve upon this model we'll use an `attention\n",
    "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
    "learn to focus over a specific range of the input sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from https://download.pytorch.org/tutorial/data.zip and unzip the file in the location of the notebook.\n",
    "    \n",
    "We'll use data/eng-fra.txt where each line in the file is a tab separated pair of English and French word sequence:\n",
    "\n",
    "    I am cold.    J'ai froid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called Lang which has word → index (word2index) and index → word (index2word) dictionaries, as well as a count of each word word2count to use to later replace rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English I added the reverse flag to reverse the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a *lot* of example sentences and we want to train\n",
    "something quickly, we'll trim the data set to only relatively short and\n",
    "simple sentences. Here the maximum length is 10 words (that includes\n",
    "ending punctuation) and we're filtering to sentences that translate to\n",
    "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
    "earlier).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['ils sont tous ici .', 'they re all here .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "\n",
    "input_tensor, target_tensor = training_pairs[0][0], training_pairs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_size,  hidden_size, vocab_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.num_layers = 2\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx = 0)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, 2, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, s0, hidden):\n",
    "        embedded = self.embedding(s0)\n",
    "        embedded = embedded.view(1,1,-1)\n",
    "        rnn_out, hidden = self.gru(embedded, hidden)\n",
    "        return rnn_out, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(2*self.num_layers, 1, self.hidden_size, device=device)\n",
    "    \n",
    "#     def initHidden(self, batch_size):\n",
    "#         return torch.randn(2*self.num_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(emb_size, hidden_size, input_lang.n_words).to(device)\n",
    "encoder_hidden = torch.randn(2*2, 1, hidden_size, device=device)\n",
    "for ei in range(input_length):\n",
    "    encoder_output, encoder_hidden = encoder1(\n",
    "        input_tensor[ei], encoder_hidden)\n",
    "    encoder_outputs[ei] = encoder_output[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([118], device='cuda:0'), torch.Size([1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[1], input_tensor[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 256])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, emb_size,  hidden_size, vocab_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.num_layers = 2\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx = 0)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, 2, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(self.num_layers*hidden_size, vocab_size) ## The output of GRU has the same length as sentence length.\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, s1, hidden):\n",
    "        embedded = self.embedding(s1)\n",
    "        embedded = F.relu(embedded)\n",
    "        embedded = embedded.view(1,1,-1)\n",
    "        rnn_out, hidden = self.gru(embedded, hidden)\n",
    "        rnn_out = self.linear(rnn_out)\n",
    "        rnn_out = self.softmax(rnn_out.squeeze(1))\n",
    "        return rnn_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = 9\n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "#def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(input_length, 2*encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_noAttn(encoder, decoder, n=10):\n",
    "    \"\"\"\n",
    "    Randomly select a English sentence from the dataset and try to produce its French translation.\n",
    "    Note that you need a correct implementation of evaluate() in order to make this function work.\n",
    "    \"\"\"    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words  = evaluate_noAttn(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 13s (- 3m 29s) (500 6%) 3.4532\n",
      "0m 27s (- 3m 14s) (1000 12%) 3.2306\n",
      "0m 41s (- 2m 59s) (1500 18%) 2.9140\n",
      "0m 55s (- 2m 45s) (2000 25%) 2.7018\n",
      "1m 9s (- 2m 32s) (2500 31%) 2.6386\n",
      "1m 22s (- 2m 18s) (3000 37%) 2.4419\n",
      "1m 36s (- 2m 4s) (3500 43%) 2.3607\n",
      "1m 50s (- 1m 50s) (4000 50%) 2.2567\n",
      "2m 4s (- 1m 36s) (4500 56%) 2.1731\n",
      "2m 18s (- 1m 22s) (5000 62%) 2.0734\n",
      "2m 32s (- 1m 9s) (5500 68%) 2.0451\n",
      "2m 46s (- 0m 55s) (6000 75%) 2.0532\n",
      "2m 59s (- 0m 41s) (6500 81%) 2.0051\n",
      "3m 13s (- 0m 27s) (7000 87%) 1.8491\n",
      "3m 27s (- 0m 13s) (7500 93%) 1.8873\n",
      "3m 41s (- 0m 0s) (8000 100%) 1.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aacb82801d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aacb81855f8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb_size = 200\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(emb_size, hidden_size, input_lang.n_words).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "#attn_decoder1 = BahdanauAttnDecoderRNN(hidden_size, output_lang.n_words, n_layers=1, dropout_p=0.1).to(device)\n",
    "decoder1 = DecoderRNN(emb_size, hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "##UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(encoder1, decoder1, 8000, print_every=500)\n",
    "\n",
    "# encoder1.load_state_dict(torch.load(\"encoder.pth\"))\n",
    "# attn_decoder1.load_state_dict(torch.load(\"attn_decoder.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_noAttn(encoder, decoder, sentence):\n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        # encode the source lanugage\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        #encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            #encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        # decode the context vector\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "        #decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(input_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            # hint: print out decoder_output and decoder_attention\n",
    "            # TODO: add your code here to populate decoded_words and decoder_attentions\n",
    "            # TODO: do this in 2 ways discussed in class: greedy & beam_search\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            # END TO DO\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words #, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elle est occupee .', 'she s busy .']\n",
      "['she', 's', 'busy', 'with', '.']\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, 500)\n",
    "eval_pairs = pairs[n]\n",
    "eval_input = eval_pairs[0]\n",
    "print(eval_pairs)\n",
    "predict = evaluate_noAttn(encoder1, decoder1, eval_input)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ils sont conscients des difficultes .\n",
      "= they are aware of the difficulties .\n",
      "< they are aware . <EOS>\n",
      "\n",
      "> nous ne sommes pas assures .\n",
      "= we re uninsured .\n",
      "< we re not evil . <EOS>\n",
      "\n",
      "> c est moi la patronne par ici .\n",
      "= i m the boss around here .\n",
      "< i m in charge here . <EOS>\n",
      "\n",
      "> je suis fatigue maintenant .\n",
      "= i m tired now .\n",
      "< i m tired of your .\n",
      "\n",
      "> je suis celle qui a construit ceci .\n",
      "= i m the one who built this .\n",
      "< i m the one one trained me . <EOS>\n",
      "\n",
      "> il passe a la radio .\n",
      "= he is on the radio .\n",
      "< he s playing to the . <EOS>\n",
      "\n",
      "> nous sommes tres proches .\n",
      "= we re very close .\n",
      "< we re very close . <EOS>\n",
      "\n",
      "> je suis desolee si je vous ai embarrassee .\n",
      "= i m sorry if i embarrassed you .\n",
      "< i m sorry if i disturbed you . <EOS>\n",
      "\n",
      "> nous sommes normaux .\n",
      "= we re normal .\n",
      "< we re stuffed . <EOS>\n",
      "\n",
      "> il n est pas marie .\n",
      "= he is unmarried .\n",
      "< he isn t married . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly_noAttn(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
